# AI
2019S


인공지능 강의 후 이론에 기반하여 구현한 코드입니다.

### ex1. Non-regularized regression

data_lab1_iis.txt 에서 데이터를 읽어 그래프에 표시합니다. linear regression parameter를 batch gradient descent(BGD), stochastic gradient
descent(SGD), closed-form method 세 가지 방식을 이용하여 각각 구한 후 결과에서 이를 비교할 수 있습니다.

![Figure_5](https://user-images.githubusercontent.com/39822788/70224168-231c2d00-1790-11ea-8a67-d178eb49b2a3.png)

blue: BGD green: SGD cyan: CFS

### ex2. Regularized regression

data_lab2_iis.txt 에서 데이터를 불러옵니다. 70%를  training data 로 사용하고 나머지 30% 를 test set 으로 사용합니다.  
optimal regression parameters을 구하기 위한 hypothesis function은 다음과 같습니다.

a) unregularized linear : red line

b) unregularized parabolic : green line

c) unregularized 5th-order polynomial : blue line

d) regularized 5th-order polynomial (RIDGE) : cyan line

![Figure_5](https://user-images.githubusercontent.com/39822788/70264115-28529980-17db-11ea-8758-c191912be354.png)


붉은 점은 traning set, 녹색 점은 test set입니다.


### ex3. Feedforward Neural Network (FFNN)  


### ex4. Feedback Neural Network  
a.k.a Recurrent Neural Network

### ex5. K-means  



